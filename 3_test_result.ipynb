{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.ired.info/\"> <img src=\"file/ired_logo.png\" alt=\"ired\" style=\"width: 150px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Classification- Test Result 物件分類 - 測試訓練結果\n",
    "\n",
    "In this notebook you will use trained model to detect whether hand sanitizer shuold be pressed.\n",
    "\n",
    "### Load the trained model 預載已訓練模型\n",
    "\n",
    "Initialize the PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the trained weights from the ``best_model_resnet18.pth`` file that you just trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('ired_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as training, you will transfer the job to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the preprocessing function 創建預處理函數\n",
    "\n",
    "Your have loaded your model, but you cannot use it yet.  The format of trained model does not completely match the format of the camera.  \n",
    "<bg> You need to do some preprocessing. The following steps will be done\n",
    "\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Scale value of [0, 1] range to [0, 255] range used by camera\n",
    "3. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display camera and create slider 顯示鏡頭及創建滑塊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have defined pre-processing function which convert images from the camera to the neural network input format.\n",
    "\n",
    "Now, try to display your camera with a slider that will display the probability that hand sanitizer should be pressed.\n",
    "<br> The slider does not display detection result yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "press_slider = widgets.FloatSlider(description='press', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, press_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update slider to show detection result  在滑塊顥示偵測結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will create a function that will get called whenever the camera's value changes.  This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. Display the camera value to slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "old_time=time.time()\n",
    "\n",
    "def update(change):\n",
    "    global press_slider, old_time, prob\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    prob_press = float(y.flatten()[0])\n",
    "    press_slider.value = prob_press\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize\n",
    "\n",
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you could check if your slider has a higher value when hand-sanitizer should be pressed, a lower value when should not be pressed.\n",
    "<br>If it behaves very different from what you expected, some problems probably happen at data collection stage.\n",
    "<br>Check the image in dataset of ``press`` and ``stop`` and ensure images are correct and clear.\n",
    "\n",
    "You need to mark down a threshold value, which hand-sanitizer will be pressed if slider displayed value is larget than (>) threshold value.\n",
    "\n",
    "For example, if you observe the slider is around 0.92 to 0.98 probability when you place a hand near it.\n",
    "You could set your threshold value to 0.9\n",
    "<br> The demo model has a thershold value of 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Your own thershold value 填寫你的模型閾值: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! You have trained a proper model to determine when hand-sanitizer should be pressed.\n",
    "Now, you will move on the motor part to control the action of pressing hand-sanitizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop camera 關閉鏡頭\n",
    "Properly stop the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--End--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
